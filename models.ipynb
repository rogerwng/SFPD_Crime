{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation of ML Models on SF Incident Report Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "Using autoencoded data for these models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(612306, 8)\n",
      "(612306,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('preprocessed_data.csv', index_col=0)\n",
    "X = data.to_numpy()\n",
    "\n",
    "labels = pd.read_csv('tree_dataset.csv', index_col=0)\n",
    "Y = labels['cat']\n",
    "enc = LabelEncoder()\n",
    "Y = enc.fit_transform(Y)\n",
    "\n",
    "del data, labels\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 2.7513173774818314\n"
     ]
    }
   ],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=500, class_weight='balanced')\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "probs = model.predict_proba(testX)\n",
    "score = log_loss(testY, probs)\n",
    "print(f'Log Loss: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 11:15:18,467] A new study created in memory with name: no-name-52fffb13-dc95-4489-b3e3-90658d801d73\n",
      "[I 2025-04-14 11:15:26,660] Trial 0 finished with value: 2.7513513173826234 and parameters: {'C': 6.680865956413374}. Best is trial 0 with value: 2.7513513173826234.\n",
      "[I 2025-04-14 11:15:34,469] Trial 1 finished with value: 2.7524488501201154 and parameters: {'C': 0.0021929924425371744}. Best is trial 0 with value: 2.7513513173826234.\n",
      "[I 2025-04-14 11:15:42,404] Trial 2 finished with value: 2.7513525353494823 and parameters: {'C': 0.7080957984901818}. Best is trial 0 with value: 2.7513513173826234.\n",
      "[I 2025-04-14 11:15:50,142] Trial 3 finished with value: 2.751354926506009 and parameters: {'C': 0.25007150117366356}. Best is trial 0 with value: 2.7513513173826234.\n",
      "[I 2025-04-14 11:15:55,681] Trial 4 finished with value: 2.7643207641807095 and parameters: {'C': 0.00022194089045665132}. Best is trial 0 with value: 2.7513513173826234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 6.680865956413374}\n",
      "2.7513513173826234\n"
     ]
    }
   ],
   "source": [
    "def lg_objective(trial):\n",
    "    params = {\n",
    "        'solver': 'lbfgs',\n",
    "        'max_iter': 500,\n",
    "        'class_weight': 'balanced',\n",
    "        'C': trial.suggest_float('C', 1e-4, 1e3, log=True)\n",
    "    }\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    total_score = 0.0\n",
    "    for idx, (train_idx, val_idx) in enumerate(kf.split(X, Y)):\n",
    "        x = X[train_idx]\n",
    "        y = Y[train_idx]\n",
    "        valx = X[val_idx]\n",
    "        valy = Y[val_idx]\n",
    "\n",
    "        model = LogisticRegression(**params)\n",
    "        model.fit(x,y)\n",
    "\n",
    "        probs = model.predict_proba(valx)\n",
    "        score = log_loss(valy, probs)\n",
    "        total_score += score\n",
    "\n",
    "        trial.report(score, idx)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    return total_score / 3\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=3)\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(lg_objective, n_trials=5)\n",
    "\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 6.057461532399648\n"
     ]
    }
   ],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=50, weights='distance')\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "probs = model.predict_proba(testX)\n",
    "score = log_loss(testY, probs)\n",
    "print(f'Log Loss: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 10:21:17,841] A new study created in memory with name: no-name-02b7ae2f-0c08-49c5-acbf-7b808306799a\n",
      "[I 2025-04-15 10:22:11,239] Trial 0 finished with value: 2.495832976583977 and parameters: {'weights': 'uniform', 'n_neighbors': 100, 'p': 2}. Best is trial 0 with value: 2.495832976583977.\n",
      "[I 2025-04-15 10:22:46,511] Trial 1 finished with value: 3.4066970589084042 and parameters: {'weights': 'uniform', 'n_neighbors': 50, 'p': 2}. Best is trial 0 with value: 2.495832976583977.\n",
      "[I 2025-04-15 10:24:25,007] Trial 2 finished with value: 2.318619977662842 and parameters: {'weights': 'uniform', 'n_neighbors': 122, 'p': 1}. Best is trial 2 with value: 2.318619977662842.\n",
      "[I 2025-04-15 10:26:29,644] Trial 3 finished with value: 4.691516879339209 and parameters: {'weights': 'distance', 'n_neighbors': 176, 'p': 1}. Best is trial 2 with value: 2.318619977662842.\n",
      "[I 2025-04-15 10:28:34,523] Trial 4 finished with value: 4.669947742172231 and parameters: {'weights': 'distance', 'n_neighbors': 190, 'p': 1}. Best is trial 2 with value: 2.318619977662842.\n",
      "[I 2025-04-15 10:29:50,777] Trial 5 finished with value: 2.1657350632123715 and parameters: {'weights': 'uniform', 'n_neighbors': 176, 'p': 2}. Best is trial 5 with value: 2.1657350632123715.\n",
      "[I 2025-04-15 10:30:40,042] Trial 6 finished with value: 2.5925087330422287 and parameters: {'weights': 'uniform', 'n_neighbors': 90, 'p': 2}. Best is trial 5 with value: 2.1657350632123715.\n",
      "[I 2025-04-15 10:31:07,677] Trial 7 finished with value: 6.597145049966528 and parameters: {'weights': 'distance', 'n_neighbors': 32, 'p': 2}. Best is trial 5 with value: 2.1657350632123715.\n",
      "[I 2025-04-15 10:31:48,128] Trial 8 finished with value: 5.393583322431418 and parameters: {'weights': 'distance', 'n_neighbors': 64, 'p': 2}. Best is trial 5 with value: 2.1657350632123715.\n",
      "[I 2025-04-15 10:32:19,827] Trial 9 finished with value: 3.7544548632046446 and parameters: {'weights': 'uniform', 'n_neighbors': 42, 'p': 2}. Best is trial 5 with value: 2.1657350632123715.\n"
     ]
    }
   ],
   "source": [
    "def knn_objective(trial):\n",
    "    params = {\n",
    "        'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "        'n_neighbors': trial.suggest_int('n_neighbors', 10, 200),\n",
    "        'p': trial.suggest_categorical('p', [1,2])\n",
    "    }\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    total_score = 0.0\n",
    "    for idx, (train_idx, val_idx) in enumerate(kf.split(X,Y)):\n",
    "        x = X[train_idx]\n",
    "        y = Y[train_idx]\n",
    "        valx = X[val_idx]\n",
    "        valy = Y[val_idx]\n",
    "\n",
    "        model = KNeighborsClassifier(**params)\n",
    "        model.fit(x,y)\n",
    "        \n",
    "        probs = model.predict_proba(valx)\n",
    "        score = log_loss(valy, probs)\n",
    "        total_score += score\n",
    "\n",
    "        trial.report(score, idx)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "    return total_score / 3\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=3)\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(knn_objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernelML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
