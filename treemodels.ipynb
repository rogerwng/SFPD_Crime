{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation of Tree Models on SF Incident Report Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "from optuna.integration import XGBoostPruningCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "Start off with initial training of target models on 80/20 train test split to see initial performance. Then move on to OOB CV and fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "DT and RF don't handle categorical's natively. Train these initial models on non-normalized, ordinal encoding dataset. Further consideration of encodings can be treated later as a fine-tuning parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month_cont</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>a_neigh</th>\n",
       "      <th>neigh</th>\n",
       "      <th>intsct</th>\n",
       "      <th>pd</th>\n",
       "      <th>sd</th>\n",
       "      <th>sd_2012</th>\n",
       "      <th>csd</th>\n",
       "      <th>cpd</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>3.52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>37.762290</td>\n",
       "      <td>-122.401324</td>\n",
       "      <td>28.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>7.23</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.30</td>\n",
       "      <td>37.753837</td>\n",
       "      <td>-122.418594</td>\n",
       "      <td>18.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>6.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>37.785893</td>\n",
       "      <td>-122.419739</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5178.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.33</td>\n",
       "      <td>37.783214</td>\n",
       "      <td>-122.410765</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9111.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Disorderly Conduct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>6.37</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.50</td>\n",
       "      <td>37.775953</td>\n",
       "      <td>-122.408846</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5583.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sex Offense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month_cont  day   time        lat        long  a_neigh  neigh  \\\n",
       "0  2023        3.52  4.0  17.50  37.762290 -122.401324     28.0   54.0   \n",
       "1  2021        7.23  6.0   8.30  37.753837 -122.418594     18.0   53.0   \n",
       "2  2021        6.13  0.0   9.67  37.785893 -122.419739     35.0   20.0   \n",
       "3  2021        7.39  1.0  12.33  37.783214 -122.410765     35.0   20.0   \n",
       "4  2019        6.37  5.0  16.50  37.775953 -122.408846     33.0   32.0   \n",
       "\n",
       "   intsct    pd    sd  sd_2012   csd  cpd                 cat  \n",
       "0   712.0   0.0  10.0     10.0   9.0  2.0             Assault  \n",
       "1  1102.0   3.0   9.0      9.0   2.0  3.0             Assault  \n",
       "2  5178.0   4.0   5.0      6.0  10.0  4.0             Assault  \n",
       "3  9111.0  10.0   5.0      6.0  10.0  5.0  Disorderly Conduct  \n",
       "4  5583.0   8.0   6.0      6.0  10.0  1.0         Sex Offense  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "treedata = pd.read_csv('tree_dataset.csv', index_col=0)\n",
    "#display(treedata.head())\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "cat_cols = ['day','a_neigh','intsct','pd'] # neigh alr encoded\n",
    "treedata_ordinal = treedata.copy()\n",
    "treedata_ordinal[cat_cols] = ord_enc.fit_transform(treedata_ordinal[cat_cols])\n",
    "display(treedata_ordinal.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 428614, Test size: 183692\n",
      "Log loss: 18.358534313380257\n"
     ]
    }
   ],
   "source": [
    "# get train test split\n",
    "train, test = train_test_split(treedata_ordinal, test_size=0.3)\n",
    "print(f'Train size: {len(train)}, Test size: {len(test)}')\n",
    "\n",
    "trainX = train.drop('cat', axis=1)\n",
    "trainY = train['cat']\n",
    "testX = test.drop('cat', axis=1)\n",
    "testY = test['cat']\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42, max_depth=25) \n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "probs = model.predict_proba(testX)\n",
    "score = log_loss(testY, probs)\n",
    "print(f'Log loss: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 3.5281388141251746\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "probs = model.predict_proba(testX)\n",
    "score = log_loss(testY, probs)\n",
    "print(f'Log loss: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 1.8146900870940692\n"
     ]
    }
   ],
   "source": [
    "treedata[cat_cols] = treedata[cat_cols].astype('category')\n",
    "X = treedata.drop('cat', axis=1)\n",
    "Y = treedata['cat']\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "Y_enc = label_enc.fit_transform(Y)\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y_enc, test_size=0.2, random_state=42)\n",
    "\n",
    "model = xgb.XGBClassifier(tree_method='hist', enable_categorical=True, eval_metric='logloss',\n",
    "                          n_estimators=80, max_depth=15, verbosity=1)\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "probs = model.predict_proba(testX)\n",
    "score = log_loss(testY, probs)\n",
    "print(f'Log loss: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/kernelML/lib/python3.9/site-packages/lightgbm/basic.py:2932: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['day', 'a_neigh', 'intsct', 'pd']\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9096\n",
      "[LightGBM] [Info] Number of data points in the train set: 489844, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -5.448822\n",
      "[LightGBM] [Info] Start training from score -2.371989\n",
      "[LightGBM] [Info] Start training from score -2.490861\n",
      "[LightGBM] [Info] Start training from score -5.659936\n",
      "[LightGBM] [Info] Start training from score -3.634227\n",
      "[LightGBM] [Info] Start training from score -3.910991\n",
      "[LightGBM] [Info] Start training from score -3.204725\n",
      "[LightGBM] [Info] Start training from score -3.015075\n",
      "[LightGBM] [Info] Start training from score -8.160200\n",
      "[LightGBM] [Info] Start training from score -3.424879\n",
      "[LightGBM] [Info] Start training from score -2.504508\n",
      "[LightGBM] [Info] Start training from score -3.399859\n",
      "[LightGBM] [Info] Start training from score -5.582150\n",
      "[LightGBM] [Info] Start training from score -7.299724\n",
      "[LightGBM] [Info] Start training from score -0.895725\n",
      "[LightGBM] [Info] Start training from score -2.299922\n",
      "[LightGBM] [Info] Start training from score -3.958390\n",
      "Log Loss: 2.198780036898451\n"
     ]
    }
   ],
   "source": [
    "treedata[cat_cols] = treedata[cat_cols].astype('category')\n",
    "X = treedata.drop('cat', axis=1)\n",
    "Y = treedata['cat']\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "Y_enc = label_enc.fit_transform(Y)\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y_enc, test_size=0.2, random_state=42)\n",
    "\n",
    "lgb_train = lgb.Dataset(trainX, label=trainY, categorical_feature=cat_cols)\n",
    "lgb_test = lgb.Dataset(testX, label=testY, categorical_feature=[cat_cols], reference=lgb_train)\n",
    "\n",
    "# lgb training params\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_class': 17,\n",
    "}\n",
    "\n",
    "model = lgb.train(params, lgb_train, valid_sets=[lgb_test])\n",
    "\n",
    "probs = model.predict(testX)\n",
    "score = log_loss(testY, probs)\n",
    "print(f'Log Loss: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.29453\n",
      "0:\tlearn: 2.1942963\ttest: 2.1945704\tbest: 2.1945704 (0)\ttotal: 3.68s\tremaining: 6m 4s\n",
      "20:\tlearn: 1.8253740\ttest: 1.8206266\tbest: 1.8206266 (20)\ttotal: 1m 37s\tremaining: 6m 5s\n",
      "40:\tlearn: 1.7974090\ttest: 1.7972357\tbest: 1.7972357 (40)\ttotal: 3m 13s\tremaining: 4m 38s\n",
      "60:\tlearn: 1.7730444\ttest: 1.7757998\tbest: 1.7757998 (60)\ttotal: 4m 54s\tremaining: 3m 8s\n",
      "80:\tlearn: 1.7590789\ttest: 1.7658269\tbest: 1.7658269 (80)\ttotal: 6m 34s\tremaining: 1m 32s\n",
      "99:\tlearn: 1.7487093\ttest: 1.7591181\tbest: 1.7591181 (99)\ttotal: 8m 11s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.759118139\n",
      "bestIteration = 99\n",
      "\n",
      "Log Loss: 1.7591181393988837\n"
     ]
    }
   ],
   "source": [
    "treedata[cat_cols] = treedata[cat_cols].astype('category')\n",
    "X = treedata.drop('cat', axis=1)\n",
    "Y = treedata['cat']\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "Y_enc = label_enc.fit_transform(Y)\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y_enc, test_size=0.2, random_state=42)\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    cat_features=cat_cols,\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='MultiClass',\n",
    "    verbose=20\n",
    ")\n",
    "\n",
    "model.fit(trainX, trainY, eval_set=(testX, testY), early_stopping_rounds=10)\n",
    "\n",
    "probs = model.predict_proba(testX)\n",
    "score = log_loss(testY, probs)\n",
    "print(f'Log Loss: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month_cont</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>a_neigh</th>\n",
       "      <th>neigh</th>\n",
       "      <th>intsct</th>\n",
       "      <th>pd</th>\n",
       "      <th>sd</th>\n",
       "      <th>sd_2012</th>\n",
       "      <th>csd</th>\n",
       "      <th>cpd</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>3.52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>37.762290</td>\n",
       "      <td>-122.401324</td>\n",
       "      <td>28.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>7.23</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.30</td>\n",
       "      <td>37.753837</td>\n",
       "      <td>-122.418594</td>\n",
       "      <td>18.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>6.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>37.785893</td>\n",
       "      <td>-122.419739</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5178.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.33</td>\n",
       "      <td>37.783214</td>\n",
       "      <td>-122.410765</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9111.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Disorderly Conduct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>6.37</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.50</td>\n",
       "      <td>37.775953</td>\n",
       "      <td>-122.408846</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5583.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sex Offense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month_cont  day   time        lat        long  a_neigh  neigh  \\\n",
       "0  2023        3.52  4.0  17.50  37.762290 -122.401324     28.0   54.0   \n",
       "1  2021        7.23  6.0   8.30  37.753837 -122.418594     18.0   53.0   \n",
       "2  2021        6.13  0.0   9.67  37.785893 -122.419739     35.0   20.0   \n",
       "3  2021        7.39  1.0  12.33  37.783214 -122.410765     35.0   20.0   \n",
       "4  2019        6.37  5.0  16.50  37.775953 -122.408846     33.0   32.0   \n",
       "\n",
       "   intsct    pd    sd  sd_2012   csd  cpd                 cat  \n",
       "0   712.0   0.0  10.0     10.0   9.0  2.0             Assault  \n",
       "1  1102.0   3.0   9.0      9.0   2.0  3.0             Assault  \n",
       "2  5178.0   4.0   5.0      6.0  10.0  4.0             Assault  \n",
       "3  9111.0  10.0   5.0      6.0  10.0  5.0  Disorderly Conduct  \n",
       "4  5583.0   8.0   6.0      6.0  10.0  1.0         Sex Offense  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "treedata = pd.read_csv('tree_dataset.csv', index_col=0)\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "cat_cols = ['day','a_neigh','intsct','pd'] # neigh alr encoded\n",
    "treedata_ordinal = treedata.copy()\n",
    "treedata_ordinal[cat_cols] = ord_enc.fit_transform(treedata_ordinal[cat_cols])\n",
    "display(treedata_ordinal.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-10 17:46:39,293] A new study created in memory with name: no-name-945005c8-d9c3-4a84-9090-f3e0f829ce2e\n",
      "[I 2025-04-10 17:46:48,729] Trial 0 finished with value: 2.713520751312558 and parameters: {'max_depth': 32, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_leaf_nodes': 11, 'criterion': 'entropy'}. Best is trial 0 with value: 2.713520751312558.\n",
      "[I 2025-04-10 17:46:59,528] Trial 1 finished with value: 2.666909725808474 and parameters: {'max_depth': 28, 'min_samples_split': 12, 'min_samples_leaf': 16, 'max_leaf_nodes': 51, 'criterion': 'gini'}. Best is trial 1 with value: 2.666909725808474.\n",
      "[I 2025-04-10 17:47:11,342] Trial 2 finished with value: 2.6575333702805786 and parameters: {'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_leaf_nodes': 70, 'criterion': 'gini'}. Best is trial 2 with value: 2.6575333702805786.\n",
      "[I 2025-04-10 17:47:22,966] Trial 3 finished with value: 2.6590737771047754 and parameters: {'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 13, 'max_leaf_nodes': 66, 'criterion': 'gini'}. Best is trial 2 with value: 2.6575333702805786.\n",
      "[I 2025-04-10 17:47:33,400] Trial 4 finished with value: 2.688209628022584 and parameters: {'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 14, 'max_leaf_nodes': 31, 'criterion': 'gini'}. Best is trial 2 with value: 2.6575333702805786.\n",
      "[I 2025-04-10 17:47:45,131] Trial 5 finished with value: 2.663856803072233 and parameters: {'max_depth': 15, 'min_samples_split': 14, 'min_samples_leaf': 18, 'max_leaf_nodes': 60, 'criterion': 'entropy'}. Best is trial 2 with value: 2.6575333702805786.\n",
      "[I 2025-04-10 17:47:55,519] Trial 6 finished with value: 2.6938368826583527 and parameters: {'max_depth': 10, 'min_samples_split': 18, 'min_samples_leaf': 16, 'max_leaf_nodes': 22, 'criterion': 'entropy'}. Best is trial 2 with value: 2.6575333702805786.\n",
      "[I 2025-04-10 17:48:06,284] Trial 7 finished with value: 2.6638826457763187 and parameters: {'max_depth': 14, 'min_samples_split': 14, 'min_samples_leaf': 7, 'max_leaf_nodes': 55, 'criterion': 'gini'}. Best is trial 2 with value: 2.6575333702805786.\n",
      "[I 2025-04-10 17:48:15,870] Trial 8 finished with value: 2.6948918992523443 and parameters: {'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_leaf_nodes': 92, 'criterion': 'entropy'}. Best is trial 2 with value: 2.6575333702805786.\n",
      "[I 2025-04-10 17:48:25,771] Trial 9 finished with value: 2.6753962248907563 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 15, 'max_leaf_nodes': 49, 'criterion': 'gini'}. Best is trial 2 with value: 2.6575333702805786.\n",
      "[I 2025-04-10 17:48:37,640] Trial 10 finished with value: 2.652323440287442 and parameters: {'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_leaf_nodes': 87, 'criterion': 'gini'}. Best is trial 10 with value: 2.652323440287442.\n",
      "[I 2025-04-10 17:48:49,526] Trial 11 finished with value: 2.651403067811132 and parameters: {'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_leaf_nodes': 89, 'criterion': 'gini'}. Best is trial 11 with value: 2.651403067811132.\n",
      "[I 2025-04-10 17:49:01,706] Trial 12 finished with value: 2.6480556331418557 and parameters: {'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 12 with value: 2.6480556331418557.\n",
      "[I 2025-04-10 17:49:13,628] Trial 13 finished with value: 2.648207658072173 and parameters: {'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_leaf_nodes': 99, 'criterion': 'gini'}. Best is trial 12 with value: 2.6480556331418557.\n",
      "[I 2025-04-10 17:49:25,667] Trial 14 finished with value: 2.6482235131167995 and parameters: {'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 98, 'criterion': 'gini'}. Best is trial 12 with value: 2.6480556331418557.\n",
      "[I 2025-04-10 17:49:37,129] Trial 15 finished with value: 2.6556519417169797 and parameters: {'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 12, 'max_leaf_nodes': 78, 'criterion': 'gini'}. Best is trial 12 with value: 2.6480556331418557.\n",
      "[I 2025-04-10 17:49:49,247] Trial 16 finished with value: 2.648015921377274 and parameters: {'max_depth': 27, 'min_samples_split': 11, 'min_samples_leaf': 10, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:50:00,802] Trial 17 finished with value: 2.6562532825370893 and parameters: {'max_depth': 29, 'min_samples_split': 11, 'min_samples_leaf': 11, 'max_leaf_nodes': 76, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:50:12,252] Trial 18 finished with value: 2.6726728606196226 and parameters: {'max_depth': 27, 'min_samples_split': 20, 'min_samples_leaf': 20, 'max_leaf_nodes': 40, 'criterion': 'entropy'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:50:23,557] Trial 19 finished with value: 2.6534234667500507 and parameters: {'max_depth': 32, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_leaf_nodes': 82, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:50:35,699] Trial 20 finished with value: 2.6483556023974795 and parameters: {'max_depth': 24, 'min_samples_split': 13, 'min_samples_leaf': 11, 'max_leaf_nodes': 97, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:50:47,478] Trial 21 finished with value: 2.648207658072173 and parameters: {'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_leaf_nodes': 99, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:50:58,963] Trial 22 finished with value: 2.6521396977889493 and parameters: {'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_leaf_nodes': 87, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:51:05,877] Trial 23 finished with value: 2.75357712278077 and parameters: {'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_leaf_nodes': 93, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:51:17,832] Trial 24 finished with value: 2.6480556331418557 and parameters: {'max_depth': 23, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:51:29,547] Trial 25 finished with value: 2.653753084982113 and parameters: {'max_depth': 26, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_leaf_nodes': 81, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:51:41,852] Trial 26 finished with value: 2.6589323209282902 and parameters: {'max_depth': 23, 'min_samples_split': 10, 'min_samples_leaf': 12, 'max_leaf_nodes': 71, 'criterion': 'entropy'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:51:53,204] Trial 27 finished with value: 2.653082025613187 and parameters: {'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_leaf_nodes': 84, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:52:05,043] Trial 28 finished with value: 2.6492608889396707 and parameters: {'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_leaf_nodes': 94, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:52:14,979] Trial 29 finished with value: 2.703135133118735 and parameters: {'max_depth': 31, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_leaf_nodes': 16, 'criterion': 'entropy'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:52:26,383] Trial 30 finished with value: 2.65639970814808 and parameters: {'max_depth': 17, 'min_samples_split': 16, 'min_samples_leaf': 13, 'max_leaf_nodes': 75, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:52:38,120] Trial 31 finished with value: 2.6484184158716015 and parameters: {'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_leaf_nodes': 98, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:52:49,653] Trial 32 finished with value: 2.648207658072175 and parameters: {'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_leaf_nodes': 99, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:53:01,525] Trial 33 finished with value: 2.651620339637529 and parameters: {'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_leaf_nodes': 88, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:53:13,418] Trial 34 finished with value: 2.6498222178990214 and parameters: {'max_depth': 24, 'min_samples_split': 12, 'min_samples_leaf': 12, 'max_leaf_nodes': 92, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:53:24,835] Trial 35 finished with value: 2.6480556331418574 and parameters: {'max_depth': 28, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:53:35,821] Trial 36 finished with value: 2.659346398852743 and parameters: {'max_depth': 26, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_leaf_nodes': 65, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:53:47,208] Trial 37 finished with value: 2.649235829638873 and parameters: {'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_leaf_nodes': 94, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:53:59,832] Trial 38 finished with value: 2.654475956814078 and parameters: {'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_leaf_nodes': 84, 'criterion': 'entropy'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:54:11,031] Trial 39 finished with value: 2.6710104210708976 and parameters: {'max_depth': 25, 'min_samples_split': 11, 'min_samples_leaf': 13, 'max_leaf_nodes': 44, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:54:21,267] Trial 40 finished with value: 2.691872935949669 and parameters: {'max_depth': 32, 'min_samples_split': 12, 'min_samples_leaf': 14, 'max_leaf_nodes': 28, 'criterion': 'gini'}. Best is trial 16 with value: 2.648015921377274.\n",
      "[I 2025-04-10 17:54:32,630] Trial 41 finished with value: 2.647750653007886 and parameters: {'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 41 with value: 2.647750653007886.\n",
      "[I 2025-04-10 17:54:43,909] Trial 42 finished with value: 2.6498014027889187 and parameters: {'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 11, 'max_leaf_nodes': 91, 'criterion': 'gini'}. Best is trial 41 with value: 2.647750653007886.\n",
      "[I 2025-04-10 17:54:55,597] Trial 43 finished with value: 2.6474022205348673 and parameters: {'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:55:07,105] Trial 44 finished with value: 2.648579741097868 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_leaf_nodes': 95, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:55:18,397] Trial 45 finished with value: 2.6498370056802307 and parameters: {'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_leaf_nodes': 90, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:55:30,386] Trial 46 finished with value: 2.6540768753293706 and parameters: {'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_leaf_nodes': 86, 'criterion': 'entropy'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:55:41,718] Trial 47 finished with value: 2.6478142298200664 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:55:52,046] Trial 48 finished with value: 2.6657275242442617 and parameters: {'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_leaf_nodes': 59, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:56:03,067] Trial 49 finished with value: 2.652998473219371 and parameters: {'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 17, 'max_leaf_nodes': 79, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:56:13,680] Trial 50 finished with value: 2.6603612048012573 and parameters: {'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 11, 'max_leaf_nodes': 90, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:56:25,834] Trial 51 finished with value: 2.647804809108046 and parameters: {'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:56:37,699] Trial 52 finished with value: 2.6484854578802723 and parameters: {'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_leaf_nodes': 96, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:56:49,100] Trial 53 finished with value: 2.6487925474108627 and parameters: {'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_leaf_nodes': 95, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:56:58,013] Trial 54 finished with value: 2.7081764532404944 and parameters: {'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:57:09,870] Trial 55 finished with value: 2.6485606497091037 and parameters: {'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 12, 'max_leaf_nodes': 96, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:57:21,332] Trial 56 finished with value: 2.650763449531676 and parameters: {'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 92, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:57:33,768] Trial 57 finished with value: 2.654191331158071 and parameters: {'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 11, 'max_leaf_nodes': 86, 'criterion': 'entropy'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:57:45,636] Trial 58 finished with value: 2.6485812066248107 and parameters: {'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_leaf_nodes': 95, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:57:54,675] Trial 59 finished with value: 2.708062924809304 and parameters: {'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_leaf_nodes': 89, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:58:06,761] Trial 60 finished with value: 2.6480159213772723 and parameters: {'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 13, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:58:18,624] Trial 61 finished with value: 2.647955425198886 and parameters: {'max_depth': 16, 'min_samples_split': 13, 'min_samples_leaf': 14, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:58:33,271] Trial 62 finished with value: 2.648454776085898 and parameters: {'max_depth': 16, 'min_samples_split': 13, 'min_samples_leaf': 14, 'max_leaf_nodes': 97, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:58:45,716] Trial 63 finished with value: 2.647928666702916 and parameters: {'max_depth': 16, 'min_samples_split': 16, 'min_samples_leaf': 16, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:58:57,210] Trial 64 finished with value: 2.649750198452184 and parameters: {'max_depth': 15, 'min_samples_split': 16, 'min_samples_leaf': 16, 'max_leaf_nodes': 92, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:59:08,800] Trial 65 finished with value: 2.64822481927301 and parameters: {'max_depth': 13, 'min_samples_split': 18, 'min_samples_leaf': 15, 'max_leaf_nodes': 97, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:59:20,103] Trial 66 finished with value: 2.6492695439605978 and parameters: {'max_depth': 17, 'min_samples_split': 15, 'min_samples_leaf': 20, 'max_leaf_nodes': 94, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:59:31,671] Trial 67 finished with value: 2.6479671992341807 and parameters: {'max_depth': 16, 'min_samples_split': 18, 'min_samples_leaf': 15, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:59:42,827] Trial 68 finished with value: 2.652646381534722 and parameters: {'max_depth': 11, 'min_samples_split': 18, 'min_samples_leaf': 18, 'max_leaf_nodes': 83, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 17:59:55,349] Trial 69 finished with value: 2.6506177149184906 and parameters: {'max_depth': 18, 'min_samples_split': 19, 'min_samples_leaf': 15, 'max_leaf_nodes': 97, 'criterion': 'entropy'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:00:06,883] Trial 70 finished with value: 2.6521794546093163 and parameters: {'max_depth': 13, 'min_samples_split': 17, 'min_samples_leaf': 17, 'max_leaf_nodes': 86, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:00:18,487] Trial 71 finished with value: 2.6479671992341807 and parameters: {'max_depth': 16, 'min_samples_split': 20, 'min_samples_leaf': 15, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:00:30,254] Trial 72 finished with value: 2.6483310295791407 and parameters: {'max_depth': 15, 'min_samples_split': 20, 'min_samples_leaf': 16, 'max_leaf_nodes': 98, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:00:42,065] Trial 73 finished with value: 2.649742974298296 and parameters: {'max_depth': 19, 'min_samples_split': 19, 'min_samples_leaf': 15, 'max_leaf_nodes': 92, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:00:53,754] Trial 74 finished with value: 2.651312050175111 and parameters: {'max_depth': 17, 'min_samples_split': 19, 'min_samples_leaf': 14, 'max_leaf_nodes': 89, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:01:05,478] Trial 75 finished with value: 2.6476726894317033 and parameters: {'max_depth': 11, 'min_samples_split': 17, 'min_samples_leaf': 17, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:01:17,530] Trial 76 finished with value: 2.648316080637298 and parameters: {'max_depth': 11, 'min_samples_split': 17, 'min_samples_leaf': 17, 'max_leaf_nodes': 97, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:01:29,331] Trial 77 finished with value: 2.6492375604415646 and parameters: {'max_depth': 14, 'min_samples_split': 15, 'min_samples_leaf': 19, 'max_leaf_nodes': 94, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:01:40,258] Trial 78 finished with value: 2.6797598571708505 and parameters: {'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 18, 'max_leaf_nodes': 36, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:01:52,186] Trial 79 finished with value: 2.6490896093272163 and parameters: {'max_depth': 12, 'min_samples_split': 17, 'min_samples_leaf': 16, 'max_leaf_nodes': 93, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:02:03,604] Trial 80 finished with value: 2.6507820327901674 and parameters: {'max_depth': 9, 'min_samples_split': 15, 'min_samples_leaf': 18, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:02:14,419] Trial 81 finished with value: 2.6669097258084777 and parameters: {'max_depth': 16, 'min_samples_split': 20, 'min_samples_leaf': 15, 'max_leaf_nodes': 51, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:02:22,900] Trial 82 finished with value: 2.743265036446684 and parameters: {'max_depth': 14, 'min_samples_split': 18, 'min_samples_leaf': 16, 'max_leaf_nodes': 10, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:02:34,762] Trial 83 finished with value: 2.647619923607277 and parameters: {'max_depth': 13, 'min_samples_split': 17, 'min_samples_leaf': 14, 'max_leaf_nodes': 100, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:02:46,708] Trial 84 finished with value: 2.6478426931591503 and parameters: {'max_depth': 10, 'min_samples_split': 18, 'min_samples_leaf': 2, 'max_leaf_nodes': 98, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:02:56,982] Trial 85 finished with value: 2.673324633352407 and parameters: {'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_leaf_nodes': 96, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:03:09,674] Trial 86 finished with value: 2.652707288372549 and parameters: {'max_depth': 11, 'min_samples_split': 17, 'min_samples_leaf': 4, 'max_leaf_nodes': 90, 'criterion': 'entropy'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:03:21,686] Trial 87 finished with value: 2.647842693159151 and parameters: {'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_leaf_nodes': 98, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:03:33,667] Trial 88 finished with value: 2.647842693159151 and parameters: {'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 3, 'max_leaf_nodes': 98, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:03:45,490] Trial 89 finished with value: 2.648027080869256 and parameters: {'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_leaf_nodes': 97, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:03:56,373] Trial 90 finished with value: 2.659414690293951 and parameters: {'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_leaf_nodes': 93, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:04:07,728] Trial 91 finished with value: 2.650141465489037 and parameters: {'max_depth': 9, 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_leaf_nodes': 98, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:04:19,468] Trial 92 finished with value: 2.6485284435638183 and parameters: {'max_depth': 13, 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_leaf_nodes': 95, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:04:31,369] Trial 93 finished with value: 2.6478426931591508 and parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_leaf_nodes': 98, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:04:42,846] Trial 94 finished with value: 2.650284859985122 and parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_leaf_nodes': 88, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:04:54,429] Trial 95 finished with value: 2.647915408289486 and parameters: {'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 98, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:05:05,363] Trial 96 finished with value: 2.6731532258893864 and parameters: {'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_leaf_nodes': 91, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:05:16,885] Trial 97 finished with value: 2.648650948090922 and parameters: {'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_leaf_nodes': 95, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:05:28,379] Trial 98 finished with value: 2.647842693159151 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_leaf_nodes': 98, 'criterion': 'gini'}. Best is trial 43 with value: 2.6474022205348673.\n",
      "[I 2025-04-10 18:05:38,056] Trial 99 finished with value: 2.69490528033825 and parameters: {'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_leaf_nodes': 93, 'criterion': 'entropy'}. Best is trial 43 with value: 2.6474022205348673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_leaf_nodes': 100, 'criterion': 'gini'}\n",
      "Best score: 2.6474022205348673\n"
     ]
    }
   ],
   "source": [
    "X = treedata_ordinal.drop(labels=['cat'], axis=1).to_numpy()\n",
    "Y = treedata_ordinal['cat'].to_numpy()\n",
    "\n",
    "def dt_objective(trial):\n",
    "    # define parameters to search thru\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 10, 100)\n",
    "    criterion =  trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "\n",
    "    # initialize model\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "        criterion=criterion,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "\n",
    "    # get cv split\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    splits = kf.split(X)\n",
    "\n",
    "    # train and validate\n",
    "    mean_scores = 0.0\n",
    "    for train_idx, val_idx in splits:\n",
    "        x = X[train_idx]\n",
    "        y = Y[train_idx]\n",
    "        valx = X[val_idx]\n",
    "        valy = Y[val_idx]\n",
    "\n",
    "        model.fit(x, y)\n",
    "        probs = model.predict_proba(valx)\n",
    "        score = log_loss(valy, probs)\n",
    "        mean_scores = mean_scores + score\n",
    "    mean_scores = mean_scores / 5\n",
    "\n",
    "    return mean_scores\n",
    "\n",
    "# train\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(dt_objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f'Best params: {best_params}')\n",
    "print(f'Best score: {study.best_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-10 21:25:58,477] A new study created in memory with name: no-name-8c8b88f1-6f35-483f-a991-518ecd88830c\n",
      "[I 2025-04-10 21:30:25,871] Trial 0 finished with value: 1.7798537826050378 and parameters: {'n_estimators': 159, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 20, 'max_features': 'log2'}. Best is trial 0 with value: 1.7798537826050378.\n",
      "[I 2025-04-10 21:37:04,884] Trial 1 finished with value: 1.722189023187346 and parameters: {'n_estimators': 178, 'max_depth': 31, 'min_samples_split': 16, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 1 with value: 1.722189023187346.\n",
      "[I 2025-04-10 21:57:58,285] Trial 2 finished with value: 1.7289113006692127 and parameters: {'n_estimators': 185, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 1 with value: 1.722189023187346.\n",
      "[I 2025-04-10 22:15:47,682] Trial 3 finished with value: 1.845533502499859 and parameters: {'n_estimators': 326, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 1 with value: 1.722189023187346.\n",
      "[I 2025-04-10 22:22:59,153] Trial 4 finished with value: 1.8806006829622195 and parameters: {'n_estimators': 392, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 13, 'max_features': 'log2'}. Best is trial 1 with value: 1.722189023187346.\n",
      "[I 2025-04-10 22:23:49,980] Trial 5 pruned. \n",
      "[I 2025-04-10 22:32:57,024] Trial 6 finished with value: 1.738063984079097 and parameters: {'n_estimators': 264, 'max_depth': 25, 'min_samples_split': 15, 'min_samples_leaf': 15, 'max_features': 'log2'}. Best is trial 1 with value: 1.722189023187346.\n",
      "[I 2025-04-10 22:39:20,902] Trial 7 pruned. \n",
      "[I 2025-04-10 22:41:36,451] Trial 8 pruned. \n",
      "[I 2025-04-10 22:42:58,991] Trial 9 pruned. \n",
      "[I 2025-04-10 23:05:13,127] Trial 10 finished with value: 1.7364377271771403 and parameters: {'n_estimators': 490, 'max_depth': 31, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 1 with value: 1.722189023187346.\n",
      "[I 2025-04-10 23:06:01,084] Trial 11 pruned. \n",
      "[I 2025-04-10 23:13:12,478] Trial 12 finished with value: 1.7262194375912674 and parameters: {'n_estimators': 202, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 1 with value: 1.722189023187346.\n",
      "[I 2025-04-10 23:23:22,985] Trial 13 finished with value: 1.7150294487205298 and parameters: {'n_estimators': 276, 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 13 with value: 1.7150294487205298.\n",
      "[I 2025-04-10 23:33:54,290] Trial 14 finished with value: 1.718997218073421 and parameters: {'n_estimators': 293, 'max_depth': 21, 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 13 with value: 1.7150294487205298.\n",
      "[I 2025-04-10 23:44:18,744] Trial 15 finished with value: 1.7194042271582908 and parameters: {'n_estimators': 288, 'max_depth': 20, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 13 with value: 1.7150294487205298.\n",
      "[I 2025-04-11 00:00:15,905] Trial 16 finished with value: 1.7099756738822016 and parameters: {'n_estimators': 409, 'max_depth': 21, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 16 with value: 1.7099756738822016.\n",
      "[I 2025-04-11 00:19:05,580] Trial 17 finished with value: 1.7091375533201152 and parameters: {'n_estimators': 467, 'max_depth': 21, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 17 with value: 1.7091375533201152.\n",
      "[I 2025-04-11 00:35:56,197] Trial 18 finished with value: 1.722126185100405 and parameters: {'n_estimators': 489, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 17 with value: 1.7091375533201152.\n",
      "[I 2025-04-11 00:42:32,630] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 467, 'max_depth': 21, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best score: 1.7091375533201152\n"
     ]
    }
   ],
   "source": [
    "X = treedata_ordinal.drop(labels='cat', axis=1).to_numpy()\n",
    "Y = treedata_ordinal['cat'].to_numpy()\n",
    "\n",
    "def rf_objective(trial):\n",
    "    # define hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 20, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt','log2'])\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        bootstrap=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # get cv split\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    splits = kf.split(X, Y)\n",
    "\n",
    "    # train and validate\n",
    "    total_scores = 0.0\n",
    "    for idx, (train_idx, val_idx) in enumerate(splits):\n",
    "        x = X[train_idx]\n",
    "        y = Y[train_idx]\n",
    "        valx = X[val_idx]\n",
    "        valy = Y[val_idx]\n",
    "\n",
    "        model.fit(x, y)\n",
    "        probs = model.predict_proba(valx)\n",
    "        score = log_loss(valy, probs)\n",
    "        total_scores = total_scores + score\n",
    "\n",
    "        # check for pruning\n",
    "        trial.report(score, step=idx)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "    return total_scores / 5\n",
    "\n",
    "# train\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=2)\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(rf_objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f'Best params: {best_params}')\n",
    "print(f'Best score: {study.best_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-11 23:36:47,306] A new study created in memory with name: no-name-f3eafbf3-cdb6-4616-8cb6-de3c23d44942\n",
      "[I 2025-04-11 23:40:29,747] Trial 0 finished with value: 2.6605469471593435 and parameters: {'n_estimators': 69, 'max_depth': 10, 'learning_rate': 0.0015708985304745703, 'subsample': 0.5334449979352542, 'colsample_bytree': 0.743364179081981, 'lambda': 0.041297585294020056, 'alpha': 0.03261340645855585}. Best is trial 0 with value: 2.6605469471593435.\n",
      "[I 2025-04-11 23:42:11,648] Trial 1 finished with value: 1.910405770992236 and parameters: {'n_estimators': 42, 'max_depth': 9, 'learning_rate': 0.0470773707913018, 'subsample': 0.7955850010943698, 'colsample_bytree': 0.6682725194508972, 'lambda': 0.00032562505331460025, 'alpha': 0.25973908728398015}. Best is trial 1 with value: 1.910405770992236.\n",
      "[I 2025-04-11 23:43:37,240] Trial 2 finished with value: 2.6397102275165376 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.002058710432932007, 'subsample': 0.927881467087298, 'colsample_bytree': 0.8321162499632044, 'lambda': 0.00415631609278744, 'alpha': 0.010400055356062308}. Best is trial 1 with value: 1.910405770992236.\n",
      "[I 2025-04-11 23:46:24,388] Trial 3 finished with value: 1.7392451700975868 and parameters: {'n_estimators': 45, 'max_depth': 12, 'learning_rate': 0.1317302863024225, 'subsample': 0.8989631976840894, 'colsample_bytree': 0.8144274976806776, 'lambda': 0.007110263879981432, 'alpha': 2.5528027948014507}. Best is trial 3 with value: 1.7392451700975868.\n",
      "[I 2025-04-11 23:59:18,850] Trial 4 finished with value: 1.7955512379687455 and parameters: {'n_estimators': 79, 'max_depth': 16, 'learning_rate': 0.03886927067962084, 'subsample': 0.8978167630329702, 'colsample_bytree': 0.8436078599741436, 'lambda': 7.432316340589349, 'alpha': 0.016267656409139276}. Best is trial 3 with value: 1.7392451700975868.\n",
      "[I 2025-04-11 23:59:34,404] Trial 5 pruned. Trial was pruned at iteration 69.\n",
      "[I 2025-04-11 23:59:35,341] Trial 6 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-12 00:07:42,797] Trial 7 finished with value: 1.7276329277661244 and parameters: {'n_estimators': 83, 'max_depth': 11, 'learning_rate': 0.2200463458033885, 'subsample': 0.9922259373726158, 'colsample_bytree': 0.6132139662631728, 'lambda': 0.35861185260417694, 'alpha': 0.005058943968113719}. Best is trial 7 with value: 1.7276329277661244.\n",
      "[I 2025-04-12 00:10:04,103] Trial 8 finished with value: 1.7477490135117801 and parameters: {'n_estimators': 33, 'max_depth': 16, 'learning_rate': 0.24107553462922068, 'subsample': 0.6793830953547926, 'colsample_bytree': 0.6955648330932769, 'lambda': 0.22191167950086288, 'alpha': 0.016699754807745795}. Best is trial 7 with value: 1.7276329277661244.\n",
      "[I 2025-04-12 00:10:04,838] Trial 9 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-12 00:10:10,803] Trial 10 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-12 00:11:32,119] Trial 11 finished with value: 1.7316053160995237 and parameters: {'n_estimators': 52, 'max_depth': 13, 'learning_rate': 0.2206630950060663, 'subsample': 0.9879022049188239, 'colsample_bytree': 0.5089503614957287, 'lambda': 0.0016105745866164007, 'alpha': 8.004978003280774}. Best is trial 7 with value: 1.7276329277661244.\n",
      "[I 2025-04-12 00:14:43,152] Trial 12 finished with value: 1.7524267169241152 and parameters: {'n_estimators': 56, 'max_depth': 14, 'learning_rate': 0.29736928287575565, 'subsample': 0.9988708528036684, 'colsample_bytree': 0.5021078233973941, 'lambda': 0.0004143200753176271, 'alpha': 0.0006403797669525743}. Best is trial 7 with value: 1.7276329277661244.\n",
      "[I 2025-04-12 00:14:44,443] Trial 13 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-12 00:14:49,805] Trial 14 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-12 00:24:38,011] Trial 15 finished with value: 1.7072941222081317 and parameters: {'n_estimators': 67, 'max_depth': 19, 'learning_rate': 0.14163877525270438, 'subsample': 0.7365240318079787, 'colsample_bytree': 0.500628249073628, 'lambda': 0.707567617688826, 'alpha': 0.0019699445302213004}. Best is trial 15 with value: 1.7072941222081317.\n",
      "[I 2025-04-12 00:24:43,929] Trial 16 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-12 00:24:48,036] Trial 17 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-12 00:24:49,302] Trial 18 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-12 00:24:54,267] Trial 19 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 67, 'max_depth': 19, 'learning_rate': 0.14163877525270438, 'subsample': 0.7365240318079787, 'colsample_bytree': 0.500628249073628, 'lambda': 0.707567617688826, 'alpha': 0.0019699445302213004}\n",
      "Best score: 1.7072941222081317\n"
     ]
    }
   ],
   "source": [
    "treedata[cat_cols] = treedata[cat_cols].astype('category')\n",
    "X = treedata.drop('cat', axis=1)\n",
    "Y = treedata['cat']\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"The reported value is ignored because this `step`.*\") # ignore warning about reporting scores\n",
    "\n",
    "# encode target\n",
    "label_enc = LabelEncoder()\n",
    "Y_enc = label_enc.fit_transform(Y)\n",
    "\n",
    "def xgb_objective(trial):\n",
    "    # Hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 20, 90)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-3, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "    l2 = trial.suggest_float('lambda', 1e-4, 10, log=True)\n",
    "    l1 = trial.suggest_float('alpha', 1e-4, 10, log=True)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': 17,\n",
    "        'tree_method': 'hist',\n",
    "        'learning_rate': learning_rate,\n",
    "        'max_depth': max_depth,\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'lambda': l2,\n",
    "        'alpha': l1,\n",
    "        'verbosity': 0,\n",
    "        'enable_categorical': True\n",
    "    }\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    total_scores = 0.0\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X, Y_enc)):\n",
    "        x_train, y_train = X.iloc[train_idx], Y_enc[train_idx]\n",
    "        x_val, y_val = X.iloc[val_idx], Y_enc[val_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train, enable_categorical=True)\n",
    "        dval = xgb.DMatrix(x_val, label=y_val, enable_categorical=True)\n",
    "\n",
    "        watchlist = [(dtrain, 'train'), (dval, 'valid')]\n",
    "\n",
    "        pruning_callback = XGBoostPruningCallback(trial, 'valid-mlogloss')\n",
    "\n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=n_estimators,\n",
    "            evals=watchlist,\n",
    "            callbacks=[pruning_callback],\n",
    "            early_stopping_rounds=20,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        preds = model.predict(dval)\n",
    "        score = log_loss(y_val, preds)\n",
    "        total_scores += score\n",
    "\n",
    "        #trial.report(score, fold_idx)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        # having alot of issues with kernel crashes due to memory, so explicitly free memory here\n",
    "        del model, dtrain, dval\n",
    "        gc.collect()\n",
    "\n",
    "    return total_scores / 3\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=1)\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(xgb_objective, n_trials=20, gc_after_trial=True)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f'Best params: {best_params}')\n",
    "print(f'Best score: {study.best_value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 15:11:44,663] A new study created in memory with name: no-name-86c74260-08c0-45b2-b020-caf88b250b61\n",
      "[I 2025-04-12 15:16:54,895] Trial 0 finished with value: 1.741943244293828 and parameters: {'learning_rate': 0.023183856662859825, 'num_leaves': 344, 'max_depth': 17, 'lambda_l1': 0.005843293254335405, 'lambda_l2': 2.4657904707348424, 'feature_fraction': 0.7223684553906875, 'bagging_fraction': 0.5643119215628734}. Best is trial 0 with value: 1.741943244293828.\n",
      "[I 2025-04-12 15:19:24,408] Trial 1 finished with value: 2.034428326304679 and parameters: {'learning_rate': 0.0002586045909739928, 'num_leaves': 348, 'max_depth': 9, 'lambda_l1': 3.7264041576182017, 'lambda_l2': 0.00019950947022326758, 'feature_fraction': 0.6679199144717741, 'bagging_fraction': 0.5331812784237497}. Best is trial 0 with value: 1.741943244293828.\n",
      "[I 2025-04-12 15:20:32,770] Trial 2 finished with value: 1.748786266036235 and parameters: {'learning_rate': 0.16557990283552415, 'num_leaves': 57, 'max_depth': 6, 'lambda_l1': 0.024502880240648815, 'lambda_l2': 2.0127185361418958, 'feature_fraction': 0.7879699211759319, 'bagging_fraction': 0.6520612271090342}. Best is trial 0 with value: 1.741943244293828.\n",
      "[I 2025-04-12 15:51:15,757] Trial 3 finished with value: 1.7229932347885926 and parameters: {'learning_rate': 0.06784242688945619, 'num_leaves': 299, 'max_depth': 18, 'lambda_l1': 0.013768256280829588, 'lambda_l2': 0.00316550020812591, 'feature_fraction': 0.616566859010482, 'bagging_fraction': 0.698816514710963}. Best is trial 3 with value: 1.7229932347885926.\n",
      "[I 2025-04-12 15:54:35,151] Trial 4 finished with value: 1.9918270219758814 and parameters: {'learning_rate': 0.0011059218321720805, 'num_leaves': 481, 'max_depth': 7, 'lambda_l1': 0.07280822016678895, 'lambda_l2': 0.05470551663704689, 'feature_fraction': 0.6556502358763378, 'bagging_fraction': 0.7088518650375171}. Best is trial 3 with value: 1.7229932347885926.\n",
      "[I 2025-04-12 15:59:34,164] Trial 5 finished with value: 1.7202555793428003 and parameters: {'learning_rate': 0.07730888755818567, 'num_leaves': 360, 'max_depth': 17, 'lambda_l1': 0.07330421866771976, 'lambda_l2': 0.19353918768108172, 'feature_fraction': 0.6906265398615845, 'bagging_fraction': 0.7872944770547323}. Best is trial 5 with value: 1.7202555793428003.\n",
      "[I 2025-04-12 16:03:31,979] Trial 6 finished with value: 1.7717266781330496 and parameters: {'learning_rate': 0.014740416529638279, 'num_leaves': 232, 'max_depth': 13, 'lambda_l1': 0.0024576979805143477, 'lambda_l2': 0.9078139838759796, 'feature_fraction': 0.8044523157464184, 'bagging_fraction': 0.526386260154398}. Best is trial 5 with value: 1.7202555793428003.\n",
      "[I 2025-04-12 16:08:44,817] Trial 7 finished with value: 1.909027312049048 and parameters: {'learning_rate': 0.002987622325253551, 'num_leaves': 355, 'max_depth': 13, 'lambda_l1': 0.004720969396908385, 'lambda_l2': 0.001303016787992572, 'feature_fraction': 0.5531028663675189, 'bagging_fraction': 0.555399754119178}. Best is trial 5 with value: 1.7202555793428003.\n",
      "[I 2025-04-12 16:15:31,536] Trial 8 finished with value: 2.0266225509475837 and parameters: {'learning_rate': 0.0002859507248260645, 'num_leaves': 325, 'max_depth': 19, 'lambda_l1': 1.159917901686882, 'lambda_l2': 0.039856187570264406, 'feature_fraction': 0.9528439583458942, 'bagging_fraction': 0.5170083723419587}. Best is trial 5 with value: 1.7202555793428003.\n",
      "[I 2025-04-12 16:23:00,817] Trial 9 finished with value: 1.875382479125874 and parameters: {'learning_rate': 0.004251744472396272, 'num_leaves': 397, 'max_depth': 13, 'lambda_l1': 0.03552138755519319, 'lambda_l2': 0.01725500626114296, 'feature_fraction': 0.5672100617930659, 'bagging_fraction': 0.8288450146744646}. Best is trial 5 with value: 1.7202555793428003.\n",
      "[I 2025-04-12 16:24:02,524] Trial 10 finished with value: 1.8046591672455297 and parameters: {'learning_rate': 0.28618410361238694, 'num_leaves': 186, 'max_depth': 3, 'lambda_l1': 0.00010308917086564854, 'lambda_l2': 0.32124460403419836, 'feature_fraction': 0.897902268971716, 'bagging_fraction': 0.9726102398892773}. Best is trial 5 with value: 1.7202555793428003.\n",
      "[I 2025-04-12 16:28:53,529] Trial 11 finished with value: 1.7285688128630978 and parameters: {'learning_rate': 0.06589207774571357, 'num_leaves': 163, 'max_depth': 17, 'lambda_l1': 0.1832414755538591, 'lambda_l2': 0.004222925188046338, 'feature_fraction': 0.6262174145407119, 'bagging_fraction': 0.8212391393217249}. Best is trial 5 with value: 1.7202555793428003.\n",
      "[I 2025-04-12 16:37:43,364] Trial 12 finished with value: 1.7056208997954174 and parameters: {'learning_rate': 0.045417206842004704, 'num_leaves': 461, 'max_depth': 20, 'lambda_l1': 0.40958473413087076, 'lambda_l2': 0.001173678228708725, 'feature_fraction': 0.5231957505420537, 'bagging_fraction': 0.7961031797590352}. Best is trial 12 with value: 1.7056208997954174.\n",
      "[I 2025-04-12 16:46:21,565] Trial 13 finished with value: 1.716209392139909 and parameters: {'learning_rate': 0.027019153311656583, 'num_leaves': 511, 'max_depth': 20, 'lambda_l1': 0.38855207557989885, 'lambda_l2': 0.00010768500270161455, 'feature_fraction': 0.5143888146492797, 'bagging_fraction': 0.8199621098473279}. Best is trial 12 with value: 1.7056208997954174.\n",
      "[I 2025-04-12 16:54:02,165] Trial 14 finished with value: 1.7347349174698525 and parameters: {'learning_rate': 0.019114394824075957, 'num_leaves': 510, 'max_depth': 20, 'lambda_l1': 0.5763339358123011, 'lambda_l2': 0.000116293792654339, 'feature_fraction': 0.501990030488705, 'bagging_fraction': 0.904719061761671}. Best is trial 12 with value: 1.7056208997954174.\n",
      "[I 2025-04-12 16:58:12,831] Trial 15 finished with value: 1.809828435921232 and parameters: {'learning_rate': 0.010940529130543119, 'num_leaves': 440, 'max_depth': 15, 'lambda_l1': 8.67577080799005, 'lambda_l2': 0.000513706889190132, 'feature_fraction': 0.5062938580801191, 'bagging_fraction': 0.8862492147745153}. Best is trial 12 with value: 1.7056208997954174.\n",
      "[W 2025-04-12 17:02:03,227] Trial 16 failed with parameters: {'learning_rate': 0.03707129149313023, 'num_leaves': 438, 'max_depth': 20, 'lambda_l1': 0.5698043557661856, 'lambda_l2': 0.0005575952717191068, 'feature_fraction': 0.57120398819363, 'bagging_fraction': 0.7453936635860884} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/kernelML/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/rl/kfwnr9bn039czmp7dm8_ycmm0000gn/T/ipykernel_30880/2152552479.py\", line 32, in lgb_objective\n",
      "    model = lgb.train(params, lgb_train, valid_sets=[lgb_test])\n",
      "  File \"/opt/miniconda3/envs/kernelML/lib/python3.9/site-packages/lightgbm/engine.py\", line 307, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"/opt/miniconda3/envs/kernelML/lib/python3.9/site-packages/lightgbm/basic.py\", line 4136, in update\n",
      "    _LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-12 17:02:03,231] Trial 16 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m pruner \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mMedianPruner(n_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_min_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     48\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, pruner\u001b[38;5;241m=\u001b[39mpruner)\n\u001b[0;32m---> 49\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlgb_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/kernelML/lib/python3.9/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/kernelML/lib/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/kernelML/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/kernelML/lib/python3.9/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/miniconda3/envs/kernelML/lib/python3.9/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m, in \u001b[0;36mlgb_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     29\u001b[0m lgb_train \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X\u001b[38;5;241m.\u001b[39miloc[train_idx], label\u001b[38;5;241m=\u001b[39mY_enc[train_idx], categorical_feature\u001b[38;5;241m=\u001b[39mcat_cols)\n\u001b[1;32m     30\u001b[0m lgb_test \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X\u001b[38;5;241m.\u001b[39miloc[val_idx], label\u001b[38;5;241m=\u001b[39mY_enc[val_idx], categorical_feature\u001b[38;5;241m=\u001b[39mcat_cols, reference\u001b[38;5;241m=\u001b[39mlgb_train)\n\u001b[0;32m---> 32\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlgb_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlgb_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X\u001b[38;5;241m.\u001b[39miloc[val_idx])\n\u001b[1;32m     35\u001b[0m score \u001b[38;5;241m=\u001b[39m log_loss(Y_enc[val_idx], probs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/kernelML/lib/python3.9/site-packages/lightgbm/engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    296\u001b[0m     cb(\n\u001b[1;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m         )\n\u001b[1;32m    305\u001b[0m     )\n\u001b[0;32m--> 307\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/kernelML/lib/python3.9/site-packages/lightgbm/basic.py:4136\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4135\u001b[0m _safe_call(\n\u001b[0;32m-> 4136\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4140\u001b[0m )\n\u001b[1;32m   4141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "treedata[cat_cols] = treedata[cat_cols].astype('category')\n",
    "X = treedata.drop('cat', axis=1)\n",
    "Y = treedata['cat']\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "Y_enc = label_enc.fit_transform(Y)\n",
    "\n",
    "def lgb_objective(trial):\n",
    "    # parameters\n",
    "    params = {\n",
    "        'objective': 'multiclass',\n",
    "        'metric': 'multi_logloss',\n",
    "        'num_class': 17,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 0.3, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 32, 512),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-4, 10, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-4, 10, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    # split\n",
    "    kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    splits = kf.split(X, Y_enc)\n",
    "    total_scores = 0.0\n",
    "    for idx, (train_idx, val_idx) in enumerate(splits):\n",
    "        lgb_train = lgb.Dataset(X.iloc[train_idx], label=Y_enc[train_idx], categorical_feature=cat_cols)\n",
    "        lgb_test = lgb.Dataset(X.iloc[val_idx], label=Y_enc[val_idx], categorical_feature=cat_cols, reference=lgb_train)\n",
    "\n",
    "        model = lgb.train(params, lgb_train, valid_sets=[lgb_test])\n",
    "\n",
    "        probs = model.predict(X.iloc[val_idx])\n",
    "        score = log_loss(Y_enc[val_idx], probs)\n",
    "        total_scores += score\n",
    "\n",
    "        trial.report(score, idx)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        del model, lgb_train, lgb_test\n",
    "        gc.collect()\n",
    "    \n",
    "    return total_scores / 3\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=3, n_min_trials=1)\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(lgb_objective, n_trials=20, gc_after_trial=True)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f'Best params: {best_params}')\n",
    "print(f'Best score: {study.best_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernelML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
